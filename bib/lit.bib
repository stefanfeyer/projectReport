@misc{Weber2018,
author = {Weber, Rebecca},
institution = {University of Konstanz},
title = {{Egocentric Motion Guidance in Mixed Reality - A comparison of visualizations guiding bilateral arm movements}},
url = {https://hci.uni-konstanz.de/typo3temp/secure{\_}downloads/90896/0/bfcef5cf9875c91f6677cd705f28b0041e08ab12/thesis{\_}weber.pdf},
year = {2018}
}
@article{Yves1987,
annote = {PMID: 15136274},
author = {Guiard, Yves},
doi = {10.1080/00222895.1987.10735426},
journal = {Journal of Motor Behavior},
number = {4},
pages = {486--517},
publisher = {Routledge},
title = {{Asymmetric Division of Labor in Human Skilled Bimanual Action}},
url = {https://doi.org/10.1080/00222895.1987.10735426},
volume = {19},
year = {1987}
}
@book{Schmalstieg2016,
author = {Schmalstieg, Dieter and H{\"{o}}llerer, Tobias},
edition = {1},
isbn = {978-0321883575},
publisher = {Addison Wesley},
title = {{Augmented Reality: Principles and Practices}},
year = {2016}
}
@article{Milgram1994,
author = {Milgram, Paul and Kishino, Fumio},
journal = {IEICE Trans. Information Systems},
pages = {1321--1329},
title = {{A Taxonomy of Mixed Reality Visual Displays}},
volume = {vol. E77-D},
year = {1994}
}
@inproceedings{Qian2005,
abstract = {We present a hybrid classification method applicable to gesture recognition. The method combines elements of Hidden Markov Models (HMM) and various Dynamic Programming Alignment (DPA) methods, such as edit distance, sequence alignment, and dynamic time warping. As opposed to existing approaches which treat HMM and DPA as either competing or complementing methods, we provide a common framework which allows us to combine ideas from both HMM and DPA research. The combined approach takes on the robustness and effectiveness of HMMs and the simplicity of DPA approaches. We have implemented and successfully tested the proposed algorithm on various gesture data.},
address = {Berlin, Heidelberg},
author = {Rajko, Stjepan and Qian, Gang},
booktitle = {Advances in Visual Computing},
editor = {Bebis, George and Boyle, Richard and Koracin, Darko and Parvin, Bahram},
isbn = {978-3-540-32284-9},
pages = {227--234},
publisher = {Springer Berlin Heidelberg},
title = {{A Hybrid HMM/DPA Adaptive Gesture Recognition Method}},
year = {2005}
}
@article{Yoshimura2006,
abstract = {Abstract In this research, the authors evaluate the degree to which dancers copy or follow the techniques of a master, or the degree of proficiency, by analyzing movements in traditional Japanese dance. The data used consist of three-dimensional time series for traditional Japanese dance movements acquired using optical motion capture system. In the authors' prior research, three moving coordinate systems which would move according to the translation and rotation of the body were used to extract the portion of the target movement. In this research, the authors consider a moving coordinate system which simultaneously takes into consideration translation, rotation, correction of orientation, and correction of waist tremble. In their prior research, the authors defined indices for movement stability and frequency characteristics as indices to quantitatively represent in an objective fashion the degree of proficiency of a dancer. Separate from this, in the current research the authors define an index with the spectrum component using a Gabor transform and an index for the amount of translation. The authors had a total of five people, a master from a particular dance school and four dance students of different genders and at different experience levels (all the master's students), perform dance experiments. The authors then extracted the target movements, measured the indices using the extraction results, and attempted to evaluate the degree of proficiency based on the proposed indices. Extraction was sufficiently precise, and the authors were able to confirm that the indices represent the differences appearing due to degree of proficiency and gender. {\textcopyright} 2005 Wiley Periodicals, Inc. Syst Comp Jpn, 37(1): 71–82, 2006; Published online in Wiley InterScience (www.interscience. wiley.com). DOI 10.1002/scj.20250},
author = {Yoshimura, Mitsu and Murasato, Hideki and Kai, Tamiko and Kuromiya, Akira and Yokoyama, Kiyoko and Hachimura, Kozaburo},
doi = {10.1002/scj.20250},
journal = {Systems and Computers in Japan},
keywords = {Gabor transform,algorithm to extract movement,degree of proficiency,traditional Japanese dance},
number = {1},
pages = {71--82},
title = {{Analysis of Japanese dance movements using motion capture system}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/scj.20250},
volume = {37},
year = {2006}
}
@article{Choensawat2015,
address = {Hingham, MA, USA},
author = {Choensawat, Worawat and Nakamura, Minako and Hachimura, Kozaburo},
doi = {10.1007/s11042-014-2209-6},
issn = {1380-7501},
journal = {Multimedia Tools Appl.},
keywords = {Dance notation,LabanEditor,Labanotation data,Movement aAnalysis},
month = {dec},
number = {23},
pages = {10823--10846},
publisher = {Kluwer Academic Publishers},
title = {{GenLaban: A Tool for Generating Labanotation from Motion Capture Data}},
url = {http://dx.doi.org/10.1007/s11042-014-2209-6},
volume = {74},
year = {2015}
}
@book{Schmidt2011,
author = {Schmidt, Richard A. and Lee, Tim},
edition = {5th Editio},
isbn = {978-0736079617},
publisher = {Human Kinetics},
title = {{Motor Control and Learning}},
year = {2011}
}
@inproceedings{Portillo2008,
abstract = {This paper presents a multimodal system capable to understand and correct in real-time the movements of Tai-Chi students through the integration of audio-visual-tactile technologies. This platform acts like a virtual teacher that transfers the knowledge of five Tai-Chi movements using feed-back stimuli to compensate the errors committed by a user during the performance of the gesture. The fundamental components of this multimodal interface are the gesture recognition system (using k-means clustering, Probabilistic Neural Networks (PNN) and Finite State Machines (FSM)) and the real-time descriptor of motion which is used to compute and qualify the actual movements performed by the student respect to the movements performed by the master, obtaining several feedbacks and compensating this movement in real-time varying audio-visualtactile parameters of different devices. The experiments of this multimodal platform have confirmed that the quality of the movements performed by the students is improved significantly.},
address = {Berlin, Heidelberg},
author = {Portillo-Rodriguez, Otniel and Sandoval-Gonzalez, Oscar O and Ruffaldi, Emanuele and Leonardi, Rosario and Avizzano, Carlo Alberto and Bergamasco, Massimo},
booktitle = {Haptic and Audio Interaction Design},
editor = {Pirhonen, Antti and Brewster, Stephen},
isbn = {978-3-540-87883-4},
pages = {30--39},
publisher = {Springer Berlin Heidelberg},
title = {{Real-Time Gesture Recognition, Evaluation and Feed-Forward Correction of a Multimodal Tai-Chi Platform}},
year = {2008}
}
@article{Rajanna2015,
abstract = {A carefully planned, structured, and supervised physiotherapy program, following a surgery, is crucial for the successful diagnosis of physical injuries. Nearly 50 {\%} of the surgeries fail due to unsupervised, and erroneous physiotherapy. The demand for a physiotherapist for an extended period is expensive to afford, and sometimes inaccessible. Researchers have tried to leverage the advancements in wearable sensors and motion tracking by building affordable, automated, physio-therapeutic systems that direct a physiotherapy session by providing audio-visual feedback on patient's performance. There are many aspects of automated physiotherapy program which are yet to be addressed by the existing systems: a wide classification of patients' physiological conditions to be diagnosed, multiple demographics of the patients (blind, deaf, etc.), and the need to pursue patients to adopt the system for an extended period for self-care. In our research, we have tried to address these aspects by building a health behavior change support system called KinoHaptics, for post-surgery rehabilitation. KinoHaptics is an automated, wearable, haptic assisted, physio-therapeutic system that can be used by a wide variety of demographics and for various physiological conditions of the patients. The system provides rich and accurate vibro-haptic feedback that can be felt by the user, irrespective of the physiological limitations. KinoHaptics is built to ensure that no injuries are induced during the rehabilitation period. The persuasive nature of the system allows for personal goal-setting, progress tracking, and most importantly life-style compatibility. The system was evaluated under laboratory conditions, involving 14 users. Results show that KinoHaptics is highly convenient to use, and the vibro-haptic feedback is intuitive, accurate, and has shown to prevent accidental injuries. Also, results show that KinoHaptics is persuasive in nature as it supports behavior change and habit building. The successful acceptance of KinoHaptics, an automated, wearable, haptic assisted, physio-therapeutic system proves the need and future-scope of automated physio-therapeutic systems for self-care and behavior change. It also proves that such systems incorporated with vibro-haptic feedback encourage strong adherence to the physiotherapy program; can have profound impact on the physiotherapy experience resulting in higher acceptance rate.},
author = {Rajanna, Vijay and Vo, Patrick and Barth, Jerry and Mjelde, Matthew and Grey, Trevor and Oduola, Cassandra and Hammond, Tracy},
doi = {10.1007/s10916-015-0391-3},
issn = {1573-689X},
journal = {Journal of Medical Systems},
month = {dec},
number = {3},
pages = {60},
title = {{KinoHaptics: An Automated, Wearable, Haptic Assisted, Physio-therapeutic System for Post-surgery Rehabilitation and Self-care}},
url = {https://doi.org/10.1007/s10916-015-0391-3},
volume = {40},
year = {2015}
}
@inproceedings{Velloso2013,
address = {New York, NY, USA},
author = {Velloso, Eduardo and Bulling, Andreas and Gellersen, Hans},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/2470654.2466171},
isbn = {978-1-4503-1899-0},
keywords = {activity assessment,learning by demonstration,motion modelling,real-time user feedback,weight lifting},
pages = {1309--1318},
publisher = {ACM},
series = {CHI '13},
title = {{MotionMA: Motion Modelling and Analysis by Demonstration}},
url = {http://doi.acm.org/10.1145/2470654.2466171},
year = {2013}
}
@inproceedings{Sousa2016,
address = {New York, NY, USA},
author = {Sousa, Maur$\backslash$'$\backslash$icio and Vieira, Jo{\~{a}}o and Medeiros, Daniel and Arsenio, Artur and Jorge, Joaquim},
booktitle = {Proceedings of the 21st International Conference on Intelligent User Interfaces},
doi = {10.1145/2856767.2856773},
isbn = {978-1-4503-4137-0},
keywords = {augmented reality,projection-based systems,rehabilitation},
pages = {175--185},
publisher = {ACM},
series = {IUI '16},
title = {{SleeveAR: Augmented Reality for Rehabilitation Using Realtime Feedback}},
url = {http://doi.acm.org/10.1145/2856767.2856773},
year = {2016}
}
@inproceedings{Tang2015,
address = {New York, NY, USA},
author = {Tang, Richard and Yang, Xing-Dong and Bateman, Scott and Jorge, Joaquim and Tang, Anthony},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
doi = {10.1145/2702123.2702401},
isbn = {978-1-4503-3145-6},
keywords = {augmented reality,movement guidance,physiotherapy,visualization},
pages = {4123--4132},
publisher = {ACM},
series = {CHI '15},
title = {{Physio@Home: Exploring Visual Guidance and Feedback Techniques for Physiotherapy Exercises}},
url = {http://doi.acm.org/10.1145/2702123.2702401},
year = {2015}
}
@inproceedings{Sodhi2012,
address = {New York, NY, USA},
author = {Sodhi, Rajinder and Benko, Hrvoje and Wilson, Andrew},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/2207676.2207702},
isbn = {978-1-4503-1015-4},
keywords = {appropriated surfaces,on-body computing,on-demand interfaces,spatial augmented reality,tracking},
pages = {179--188},
publisher = {ACM},
series = {CHI '12},
title = {{LightGuide: Projected Visualizations for Hand Movement Guidance}},
url = {http://doi.acm.org/10.1145/2207676.2207702},
year = {2012}
}
@inproceedings{Hoang2016,
address = {New York, NY, USA},
author = {Hoang, Thuong N and Reinoso, Martin and Vetere, Frank and Tanin, Egemen},
booktitle = {Proceedings of the 9th Nordic Conference on Human-Computer Interaction},
doi = {10.1145/2971485.2971521},
isbn = {978-1-4503-4763-1},
keywords = {Virtual reality,first person view,posture guidance},
pages = {25:1----25:10},
publisher = {ACM},
series = {NordiCHI '16},
title = {{Onebody: Remote Posture Guidance System Using First Person View in Virtual Environment}},
url = {http://doi.acm.org/10.1145/2971485.2971521},
year = {2016}
}
@inproceedings{Chan2007,
address = {ICST, Brussels, Belgium, Belgium},
author = {Chan, Jacky and Leung, Howard and Tang, Kai Tai and Komura, Taku},
booktitle = {Proceedings of the First International Conference on Immersive Telecommunications},
isbn = {978-963-9799-06-6},
keywords = {3d human motion analysis,human computer interaction,immersive VR application,performance training},
pages = {7:1----7:6},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
series = {ImmersCom '07},
title = {{Immersive Performance Training Tools Using Motion Capture Technology}},
url = {http://dl.acm.org/citation.cfm?id=1538981.1538991},
year = {2007}
}
@inproceedings{Katzakis2017,
address = {New York, NY, USA},
author = {Katzakis, Nicholas and Tong, Jonathan and Ariza, Oscar and Chen, Lihan and Klinker, Gudrun and R{\"{o}}der, Brigitte and Steinicke, Frank},
booktitle = {Proceedings of the 5th Symposium on Spatial User Interaction},
doi = {10.1145/3131277.3132181},
isbn = {978-1-4503-5486-8},
keywords = {haptic,integration,interface,multisensory,perception,posture training,sensory,visual,wearable},
pages = {58--67},
publisher = {ACM},
series = {SUI '17},
title = {{Stylo and Handifact: Modulating Haptic Perception Through Visualizations for Posture Training in Augmented Reality}},
url = {http://doi.acm.org/10.1145/3131277.3132181},
year = {2017}
}
@inproceedings{Han2016,
address = {New York, NY, USA},
author = {Han, Ping-Hsuan and Chen, Kuan-Wen and Hsieh, Chen-Hsin and Huang, Yu-Jie and Hung, Yi-Ping},
booktitle = {Proceedings of the 7th Augmented Human International Conference 2016},
doi = {10.1145/2875194.2875237},
isbn = {978-1-4503-3680-2},
keywords = {Augmented Reality,Body Movement Guidance,Visualization,Wearable Interaction},
pages = {31:1----31:4},
publisher = {ACM},
series = {AH '16},
title = {{AR-Arm: Augmented Visualization for Guiding Arm Movement in the First-Person Perspective}},
url = {http://doi.acm.org/10.1145/2875194.2875237},
year = {2016}
}
@inproceedings{Han2017,
address = {New York, NY, USA},
author = {Han, Ping-Hsuan and Chen, Yang-Sheng and Zhong, Yilun and Wang, Han-Lei and Hung, Yi-Ping},
booktitle = {Proceedings of the 8th Augmented Human International Conference},
doi = {10.1145/3041164.3041194},
isbn = {978-1-4503-4835-5},
keywords = {Tai-Chi Chuan,augmented mirror,drone,mixed reality,physical activity learning},
pages = {25:1----25:4},
publisher = {ACM},
series = {AH '17},
title = {{My Tai-Chi Coaches: An Augmented-learning Tool for Practicing Tai-Chi Chuan}},
url = {http://doi.acm.org/10.1145/3041164.3041194},
year = {2017}
}
@inproceedings{Covaci2014,
address = {New York, NY, USA},
author = {Covaci, Alexandra and Olivier, Anne-H{\'{e}}l{\`{e}}ne and Multon, Franck},
booktitle = {Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology},
doi = {10.1145/2671015.2671023},
isbn = {978-1-4503-3253-8},
keywords = {basketball training,immersive room,perception of distance in VR,performance,visual feedback},
pages = {55--64},
publisher = {ACM},
series = {VRST '14},
title = {{Third Person View and Guidance for More Natural Motor Behaviour in Immersive Basketball Playing}},
url = {http://doi.acm.org/10.1145/2671015.2671023},
year = {2014}
}
@inproceedings{Kojima2014,
abstract = {The basic of training physical skills is to imitate instructor's motion. Observation is the very first step to copy the motion of instructor when at the beginning of learning sports of artisanship. However, beginners face difficulties in imitating at the start since they do not have somesthetic image of the movement. In order to help learning physical skills, we propose Immersive virtual environment using head mounted display that indicates 3D motion of instructor super imposed on learner's body. By using this system, learners try to match its own form to instructor's 3D model to imitate instructor's motion from first person view in virtual environment. At the early stage of this research, we tried to transfer pitching skill in baseball. We evaluated the effectiveness of proposed system by measuring throwing distance.},
address = {Cham},
author = {Kojima, Taihei and Hiyama, Atsushi and Miura, Takahiro and Hirose, Michitaka},
booktitle = {Human Interface and the Management of Information. Information and Knowledge in Applications and Services},
editor = {Yamamoto, Sakae},
isbn = {978-3-319-07863-2},
pages = {51--58},
publisher = {Springer International Publishing},
title = {{Training Archived Physical Skill through Immersive Virtual Environment}},
year = {2014}
}
@inproceedings{Yan2015,
address = {New York, NY, USA},
author = {Yan, Shuo and Ding, Gangyi and Guan, Zheng and Sun, Ningxiao and Li, Hongsong and Zhang, Longfei},
booktitle = {Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems},
doi = {10.1145/2702613.2732759},
isbn = {978-1-4503-3146-3},
keywords = {augmented human,choreography,external self-image,mixed reality,visual blending},
pages = {965--970},
publisher = {ACM},
series = {CHI EA '15},
title = {{OutsideMe: Augmenting Dancer's External Self-Image by Using A Mixed Reality System}},
url = {http://doi.acm.org/10.1145/2702613.2732759},
year = {2015}
}
@inproceedings{Scavo2015,
author = {Scavo, Giuseppe and Wild, Fridolin and Scott, Peter},
booktitle = {Workshop Proceedings of the 11th International Conference on Intelligent Environments},
pages = {236--243},
title = {{No Title}},
year = {2015}
}
@article{Chinthammit2014,
author = {Chinthammit, Winyu and Merritt, Troy and Scott, Pedersen and Andrew, Williams and Denis, Visentin and Rowe, Robert and Thomas, Furness},
journal = {BioMed Research International},
title = {{Ghostman: Augmented Reality Application for Telerehabilitation and Remote Instruction of a Novel Motor Skill}},
volume = {2014},
year = {2014}
}
@article{Lieberman2007,
author = {Lieberman, J and Breazeal, C},
doi = {10.1109/TRO.2007.907481},
journal = {IEEE Transactions on Robotics},
keywords = {5-DOF robotic suit,Acceleration,Education,Educational robots,Human factors,Humans,Intelligent robots,Intelligent systems,Joints,Learning systems,Optical feedback,Real time systems,TIKL,auditory feedback,feedback,haptic interfaces,human motor learning,intelligent tutoring systems,kinesthetic learning,man–machine systems,motor rehabilitation,real-time systems,realtime tactile feedback,robot tactile systems,robots,sports training,visual feedback,wearable computers,wearable robotic system,wearable vibrotactile feedback suit},
month = {oct},
number = {5},
pages = {919--926},
title = {{TIKL: Development of a Wearable Vibrotactile Feedback Suit for Improved Human Motor Learning}},
volume = {23},
year = {2007}
}
@inproceedings{Hachimura2004,
author = {Hachimura, K and Kato, H and Tamura, H},
booktitle = {RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759)},
doi = {10.1109/ROMAN.2004.1374759},
keywords = {Character generation,Cultural differences,Education,Facial animation,Humans,Layout,Motion measurement,Motion pictures,Prototypes,Virtual reality,computer based training,computer graphics,dance education,humanities,interactive systems,mixed reality technology,motion capture technology,prototype dance training support system,prototypes,real world scenes,user interface functions,user interfaces,virtual reality,virtual world scenes},
pages = {217--222},
title = {{A prototype dance training support system with motion capture and mixed reality technologies}},
year = {2004}
}
@article{Yang2002,
author = {Yang, Ungyeon and Kim, Gerard Jounghyn},
journal = {Presence},
number = {No. 3},
pages = {304--323},
title = {{Implementation and Evaluation of "Just Follow Me": An Immersive, VR-Based, Motion-Training System}},
volume = {11},
year = {2002}
}
@article{Chan2010,
author = {Chan, J C P and Leung, H and Tang, J K T and Komura, T},
doi = {10.1109/TLT.2010.27},
journal = {IEEE Transactions on Learning Technologies},
keywords = {Animation,Color,Games,Joints,Rendering (computer graphics),Three dimensional displays,Training,computer aided instruction,computer uses in education,humanities,motion analysis.,motion capture technology,movement learning,virtual reality,virtual reality dance training system,virtual teacher},
month = {apr},
number = {2},
pages = {187--195},
title = {{A Virtual Reality Dance Training System Using Motion Capture Technology}},
volume = {4},
year = {2010}
}
@inproceedings{Chua2003,
author = {{Philo Tan Chua} and Crivella, R and Daly, B and {Ning Hu} and Schaaf, R and Ventura, D and Camill, T and Hodgins, J and Pausch, R},
booktitle = {IEEE Virtual Reality, 2003. Proceedings.},
doi = {10.1109/VR.2003.1191125},
keywords = {Animation,Displays,Optical feedback,Testing,Tracking,User interfaces,Virtual environment,Virtual prototyping,Virtual reality,Wires,animated representation,belt-worn video receiver,computer based training,full body Tai Chi training application,head-mounted display,helmet mounted displays,immersive techniques,mobile computing,motion training tasks,physical task training,sport,user interface,user interfaces,virtual environments,virtual reality,virtual teacher,wireless virtual reality system},
month = {mar},
pages = {87--94},
title = {{Training for physical tasks in virtual environments: Tai Chi}},
year = {2003}
}
@inproceedings{Anderson2013a,
address = {New York, NY, USA},
author = {Anderson, Fraser and Grossman, Tovi and Matejka, Justin and Fitzmaurice, George},
booktitle = {Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/2501988.2502045},
isbn = {978-1-4503-2268-3},
keywords = {3d,augmented reality,full body,guidance.,learning,motor learning,movement,training},
pages = {311--320},
publisher = {ACM},
series = {UIST '13},
title = {{YouMove: Enhancing Movement Training with an Augmented Reality Mirror}},
url = {http://doi.acm.org/10.1145/2501988.2502045},
year = {2013}
}
@book{author,
title = {{No Title}}
}
@misc{LaViola2017,
address = {Boston },
annote = {QA76.9.U83},
author = {LaViola, Joseph J},
edition = {Second },
isbn = {0134034325;9780134034478;9780134034324;0134034473;},
keywords = {Three-dimensional display systems,User interfaces (Computer systems),Virtual reality},
publisher = {Addison-Wesley },
title = {{3D user interfaces: theory and practice }},
url = {http://konstanz.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV3LisMgFL102s3AQF8zzPRF-gEN0WsSXfdBobvSrouJZtlFH{\_}9fr00mtNC6E0VQ0HM8HI8AyMNo9nQmcM1ytMxggTlqmWQsNo6oSpsUKpEmfjJfVEpGdTqGFGgannXh7o9EPs{\_}3GAlyYVCCDkPhk-vkB7QcIqVk7Vts97XWogQZ1n2iju-KPK4rIsUyia},
year = {2017}
}
@book{LaViola,
abstract = {Second edition. "From video games to mobile augmented reality, 3D interaction is everywhere. But simply choosing to use 3D input or 3D displays isn't enough: 3D user interfaces (3D UIs) must be carefully designed for optimal user experience. 3D User Interfaces: Theory and Practice, Second Edition is today's most comprehensive primary reference to building outstanding 3D UIs. Four pioneers in 3D user interface research and practice have extensively expanded and updated this book, making it today's definitive source for all things related to state-of-the-art 3D interaction."--Publisher's website. Part I. Foundations of 3D User Interfaces : -- Part II. Human factors and Human-Computer Interaction Basics : -- Part III. Hardware Technologies for 3D User Interfaces : -- Part IV. 3D Interaction Techniques : -- Part V. Designing and Developing 3D User Interfaces : -- Part VI. The Future of OF 3D Interfaces. Foreword to the Second Edition -- Foreword to the First Edition -- Preface to the Second Edition -- Preface to the First Edition -- Acknowledgments -- About the Authors -- Part I. Foundations of 3D User Interfaces : -- 1. Introduction to 3D User Interfaces -- 1.1. What Are 3D User Interfaces? -- 1.2. Why 3D User Interfaces? -- 1.3. Terminology -- 1.4. Application Areas -- 1.5. Conclusion{\{}Chapter{\}} -- 2. 3D User Interfaces: History and Roadmap -- 2.1. History of 3D UIs -- 2.2. Roadmap to 3D UIs -- 2.3. Scope of this Book -- 2.4. Introduction to Case Studies -- 2.5. Conclusion -- Part II. Human factors and Human-Computer Interaction Basics : -- 3. Human Factors Fundamentals -- 3.1. Introduction -- 3.2. Information Processing -- 3.3. Perception -- 3.4. Cognition -- 3.5. Physical Ergonomics -- 3.6. Guidelines -- 3.7. Conclusion -- Recommended Reading -- 4. General Principles of Human-Computer Interaction -- 4.1. Introduction -- 4.2. Understanding the User Experience -- 4.3. Design Principles and Guidelines -- 4.4. Engineering the User Experience -- 4.5. Conclusion -- Recommended Reading -- Part III. Hardware Technologies for 3D User Interfaces : -- 5. 3D User Interface Output Hardware -- 5.1. Introduction -- 5.2. Visual Displays -- 5.3. Auditory Displays -- 5.4. Haptic Displays -- 5.5. Characterizing Displays by Level of Fidelity -- 5.6. Design Guidelines: Choosing Output Devices for 3D User Interfaces -- 5.7. Case Studies -- 5.8. Conclusion -- Recommended Reading -- 6. 3D User Interface Input Hardware -- 6.1. Introduction -- 6.2. Traditional Input Devices -- 6.3. 3D Spatial Input Devices -- 6.4. Complementary Input for 3D User Interfaces -- 6.5. Special-Purpose Input Devices -- 6.6. Do It Yourself (DIY) Input Devices -- 6.7. Choosing Input Devices for 3D User Interfaces -- 6.8. Case Studies -- 6.9. Conclusion -- Recommended Reading. Part IV. 3D Interaction Techniques : -- 7. Selection and Manipulation -- 7.1. Introduction -- 7.2. 3D Manipulation Tasks -- 7.3. Classifications for 3D Manipulation -- 7.4. Grasping Metaphors -- 7.5. Pointing Metaphors -- 7.6. Surface Metaphors -- 7.7. Indirect Metaphors -- 7.8. Bimanual Metaphors -- 7.9. Hybrid Metaphors -- 7.10. Other Aspects of 3D Manipulation -- 7.11. Design Guidelines -- 7.12. Case Studies -- 7.13. Conclusion -- Recommended Reading -- 8. Travel -- 8.1. Introduction -- 8.2. 3D Travel Tasks -- 8.3. Classifications for 3D Travel -- 8.4. Walking Metaphors -- 8.5. Steering Metaphors -- 8.6. Selection-Based Travel Metaphors -- 8.7. Manipulation-Based Travel Metaphors -- 8.8. Other Aspects of Travel Techniques -- 8.9. Wayfinding in 3D Environments -- 8.10. Design Guidelines -- 8.11. Case Studies -- 8.12. Conclusion -- Recommended Reading -- 9. System Control -- 9.1. Introduction -- 9.2. System Control Issues -- 9.3. Classification -- 9.4. Physical Controllers -- 9.5. Graphical Menus -- 9.6. Voice Commands -- 9.7. Gestural Commands -- 9.8. Tools -- 9.9. Multimodal Techniques -- 9.10. Design Guidelines -- 9.11. Case Studies -- 9.12. Conclusion -- Recommended Reading -- Part V. Designing and Developing 3D User Interfaces : -- 10. Strategies in Designing and Developing 3D User Interfaces -- 10.1. Introduction -- 10.2. Designing for Humans -- 10.3. Inventing 3D User Interfaces -- 10.4. Design Guidelines -- 10.5. Case Studies -- 10.6. Conclusion -- Recommended Reading -- 11. Evaluation of 3D User Interfaces -- 11.1. Introduction -- 11.2. Evaluation Methods for 3D UIs -- 11.3. Evaluation Metrics for 3D UIs -- 11.4. Characteristics of 3D UI Evaluations -- 11.5. Classification of Evaluation Methods -- 11.6. Three Multimethod Approaches -- 11.7. Guidelines for 3D UI Evaluation -- 11.8. Case Studies -- 11.9. Conclusion -- Recommended Reading -- Acknowledgment -- Part VI. The Future of OF 3D Interfaces : -- 12. The Future of 3D User Interfaces -- 12.1. User Experience with 3D Displays -- 12.2. 3D UI Design -- 12.3. 3D UI Development and Evaluation -- 12.4. 3D UIs in the Real World -- 12.5. Applications of 3D UIs -- Bibliography -- Index.},
author = {LaViola, Joseph J.},
isbn = {9780134034324},
title = {{3D user interfaces : theory and practice}}
}
@article{Mine,
author = {Mine, Norio and Kai, Tamiko},
isbn = {0780372220},
pages = {188--193},
title = {{Quantification of Characteristic Features of Japanese Dance for}}
}
@book{Schmidt2011,
abstract = {Most of us have marveled at one time or another about how highly skilled performers in industry, sport, music, or dance seem to make their actions appear so simple and easy, performed with incredible efficiency, smoothness, style, and grace. Like the first three editions (Schmidt, 1982,1988; Schmidt {\&} Lee, 1999), the fourth edition of Motor Control and Learning: A Behavioral Emphasis was written for those who would like to understand how it is that these performers can achieve such artistry while we, as beginners in a similar task, are clumsy, inept, and unskilled. This book was written particularly as a textbook for university or college undergraduate and graduate students taking courses in human performance or motor learning, primarily in fields such as kinesiology or psychology. Students in other fields such as the neurosciences, physical and occupational therapy, biomedical or industrial engineering, and human factors/ergonomics will also find many of the concepts contained here to be of interest, as movement behavior is a part of all of them. And for those who are (or are becoming) practitioners in these fields, the principles of motor behavior outlined here should provide a solid basis for tasks such as designing human-machine systems, developing training programs in sport or industry, or teaching progressions in dance or music. The book is divided into three parts. Part I provides an introduction to research and fundamental concepts that are important to understanding motor behavior; Part II deals with motor control; and Part III deals with the acquisition of skill, or motor learning. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
author = {Schmidt, Richard and Lee, Tim},
isbn = {0736079610},
title = {{Motor Control and Learning: A Behavioral Approach}},
year = {2011}
}
@article{Yang2006,
abstract = {We present a study of collaborative dancing between remote dancers in a tele-immersive environment which features 3D full and real body capturing, wide field of view, multi-display 3D rendering, and attachment free participant. We invite two professional dancers to perform collaborative dancing in the environment. The coordination requires one dancer to take the lead while the other follows by appropriate movement. Throughout the experiment, the dancers are dancing at various motion rates to evaluate how well the collaborative dancing is supported with the current technical boundary. Our important findings indicate that 1) tele-immersive environments have strong potential impact on the concept of choreography and communication of live dance performance, 2) the presence of multi-view display, real body 3D rendering, audio channel, and less intrusiveness greatly enhances the immersive and dancing experience, and 3) the level of synchronization achieved by the dancers is higher than that expected from the video rate.},
author = {Yang, Zhenyu and Yu, Bin and Wu, Wanmin and Diankov, Ross and Bajscy, Ruzena},
doi = {10.1038/nature08600},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2006 - Collaborative dancing in tele-immersive environment.pdf:pdf},
isbn = {1595934472},
issn = {00280836},
journal = {Proceedings of the 14th annual ACM international conference on Multimedia  - MULTIMEDIA '06},
keywords = {3d tele-immersive environment,collaboration,dance},
pages = {723},
title = {{Collaborative dancing in tele-immersive environment}},
url = {http://portal.acm.org/citation.cfm?doid=1180639.1180793},
year = {2006}
}
@article{Magnenat-thalmann1990,
author = {Magnenat-thalmann, Nadia and Joslin, Chris},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Magnenat-thalmann, Joslin - 1990 - Learning how to Dance on the Internet.pdf:pdf},
keywords = {7,advanced interactivity,called dvs,commercial system,dance,humans,internet,networked virtual environments,teaching,virtual,was developed as a},
number = {May},
title = {{Learning how to Dance on the Internet}},
year = {1990}
}
@article{Kwon2005,
abstract = {We present a new framework to build motion training systems using machine learning techniques. The goal of our approach is the design of a training method based on the combination of body and visual sensors. We introduce the concept of a Motion Chunk to analyze human motion and construct a motion data model in real-time. The system provides motion detection and evaluation and visual feedback generation. We discuss the results of user tests regarding the system efficiency in martial art training. With our system, trainers can generate motion training videos and practice complex motions precisely evaluated by a computer.},
author = {Kwon, Doo Young and Gross, Markus},
doi = {10.1145/1178477.1178490},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kwon, Gross - 2005 - Combining body sensors and visual sensors for motion training.pdf:pdf},
isbn = {1595931104},
journal = {Proceedings of the 2005 ACM SIGCHI International Conference on Advances in computer entertainment technology  - ACE '05},
keywords = {body sensor,mo-,motion analysis,motion training system,tion chunk,visual feedback,visual sensor},
pages = {94--101},
title = {{Combining body sensors and visual sensors for motion training}},
url = {http://portal.acm.org/citation.cfm?doid=1178477.1178490},
year = {2005}
}
@article{Alankus2005,
abstract = {In this paper, we present a technique to automatically synthesize dancing motions for arbitrary songs with dance beats. Our technique is based on analysing a musical tune (can be a song or melody) and synthesizing a motion for the virtual character where the character's movement synchronizes to the musical beats. In order to analyse beats of the tune, we developed a fast algorithm. Our motion synthesis algorithm analyses library of stock motions and generates new sequences of movements that were not described in the library. We show that our motion synthesis algorithm is better than previous dance generation techniques. We also present two algorithms to synchronize dance moves and musical beats: a fast greedy algorithm, and a genetic algorithm. Our experimental results show that we can generate new sequences of dance figures in which the dancer reacts to music and dances in synchronization with the music.},
author = {Alankus, Gazihan and {Alphan Bayazit}, A. and {Burchan Bayazit}, O.},
doi = {10.1002/cav.99},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alankus, Alphan Bayazit, Burchan Bayazit - 2005 - Automated motion synthesis for dancing characters.pdf:pdf},
issn = {15464261},
journal = {Computer Animation and Virtual Worlds},
keywords = {Beat analysis,Motion analysis,Motion interpolation,Motion synthesis,Virtual choreography},
number = {3-4},
pages = {259--271},
title = {{Automated motion synthesis for dancing characters}},
volume = {16},
year = {2005}
}
@article{Magnenat-thalmann2008,
abstract = {Preserving the knowledge of previous generations and passing it to new generations is challenging. This process is usually based on an educational system or in any other kind of face-to-face tradition. However, developing countries usually face a lack of well educated people so that this process is hindered. This is even more problematic for countries having recently struggled through times of war. Hence, we apply a community-centered approach to capturing expert knowledge in non-linear digital stories and repurposing it in the shape of educational games. In particular, we support the vocational training of local employees within a cultural heritage community that aims at preserving Bamiyan Valley in Afghanistan.},
archivePrefix = {arXiv},
arxivId = {9780201398298},
author = {Magnenat-thalmann, Nadia and Protopsaltou, Dimitrios and Kavakli, Evangelia},
doi = {10.1007/978-3-540-85033-5},
eprint = {9780201398298},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Magnenat-thalmann, Protopsaltou, Kavakli - 2008 - Advances in Web Based Learning - ICWL 2008.pdf:pdf},
isbn = {978-3-540-85032-8},
issn = {03029743},
number = {May 2014},
pmid = {4520227},
title = {{Advances in Web Based Learning - ICWL 2008}},
url = {http://link.springer.com/10.1007/978-3-540-85033-5},
volume = {5145},
year = {2008}
}
@article{Soga2009,
abstract = {We have developed an automatic composition system for contemporary dance by using 3D motion clips. Our goal is to develop some useful tools in dance education such as creation-support system for teachers and self-study system for students. Our approach is not creating natural connection but creating conceptual sequences using basic motions of contemporary dance. We present an experiment to assess whether sequences randomly selected would be appropriate for contemporary dance training and to determine some effective elements to integrate into the algorithm. As a result of the experiment, our proposed system was found to be useful and helpful for dance training.},
author = {Soga, Asako and Umino, Bin and Hirayama, Motoko},
doi = {10.1109/CW.2009.37},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Soga, Umino, Hirayama - 2009 - Automatic composition for contemporary dance using 3D motion clips Experiment on dance training and syste.pdf:pdf},
isbn = {9780769537917},
journal = {2009 International Conference on CyberWorlds, CW '09},
pages = {171--176},
pmid = {70648030},
title = {{Automatic composition for contemporary dance using 3D motion clips: Experiment on dance training and system evaluation}},
year = {2009}
}
@article{Brockhoeft2016,
abstract = {" Like the overlap in a Venn diagram, shared kinesthetic and intellectual constructs from the field of dance and the field of technology will reinforce and enhance one another, resulting in an ultimately deepened experience for both viewer and performer. " -Alyssa Schoeneman Abstract With the rise of the digital age, dancers and choreog-raphers started looking for new ways to connect with younger audiences who were left disengaged from tra-ditional dance productions. This led to the growing pop-ularity of multimedia performances where digitally pro-jected spaces appear to be influenced by dancers' move-ments. Unfortunately current approaches, such as re-liance on pre-rendered videos, merely create the illusion of interaction with dancers, when in fact the dancers are actually closely synchronized with the multimedia display to create the illusion. This calls for unprece-dented accuracy of movement and timing on the part of the dancers, which increases cost and rehearsal time, as well as greatly limits the dancers' creative expression. We propose the first truly interactive solution for inte-grating digital spaces into dance performance: ViFlow. Our approach is simple, cost effective, and fully interac-tive in real-time, allowing the dancers to retain full free-dom of movement and creative expression. In addition, our system eliminates reliance on a technical expert. A movement-based language enables choreographers to directly interact with ViFlow, empowering them to inde-pendently create fully interactive, live augmented real-ity productions.},
author = {Brockhoeft, Taylor and Petuch, Jennifer and Bach, James and Djerekarov, Emil and Ackerman, Margareta and Tyson, Gary},
doi = {10.1007/BF01533262},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brockhoeft et al. - 2016 - Interactive Augmented Reality for Dance.pdf:pdf},
isbn = {978-274-669-155-1},
journal = {Proceedings of the Seventh International Conference on Computational Creativity (ICCC 2016)},
number = {June},
pages = {396--403},
title = {{Interactive Augmented Reality for Dance}},
url = {http://www.computationalcreativity.net/iccc2016/wp-content/uploads/2016/01/Interactive-Augmented-Reality-for-Dance.pdf},
year = {2016}
}
@article{Davcev2003,
abstract = {We emphasize the generation of an augmented reality environment of a single dancer based on analysis of dance annotations. We introduce a new Web3D-based interactive technique for dance animation needed for educational purposes. This approach offers new possibilities for interactive dance step observation, slow movements of fast steps, different angles of view and several functions as a support of high interactivity between the user and the 3D dancer. The benefits of the approach have been estimated by dance experts from the Macedonian Folklore Institute, and the "Mirche Acev" folk ensemble.},
author = {Davcev, D. and Trajkovic, V. and Kalajdziski, S. and Celakoski, S.},
doi = {10.1109/ITRE.2003.1270600},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Davcev et al. - 2003 - Augmented reality environment for dance learning.pdf:pdf},
isbn = {0780377249},
journal = {Proceedings, ITRE 2003 - International Conference on Information Technology: Research and Education},
pages = {189--193},
title = {{Augmented reality environment for dance learning}},
year = {2003}
}
@article{Komura2006,
abstract = {Traditionally, when people want to learn martial arts, they have to go to training clubs and learn under the coach together with the other students. To reduce the tuition fees, there are usually a lot of students under a single coach and hence, it is difficult for the students to get enough suggestions in the class. It would be far easier if the students could practice themselves at home and ask for suggestions from a virtual coach in the computer. Occasionally, in case they find difficulties going to the next step, they may then approach the real coach for suggestions and training. In this paper, we propose such a training system based on the motion capture system. The system automatically analyzes the motions of the player and gives suggestions. The students can also view the martial art techniques stored in the system or their own techniques captured by the motion capture system from various points of view in order to gain objective ideas of the techniques.},
author = {Komura, Taku and Lam, Beta and Lau, R W H and Leung, Howard},
doi = {10.1007/11925293_22},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2006 - e-Learning Martial Arts.pdf:pdf},
isbn = {3-540-49027-2},
issn = {0302-9743},
journal = {Lncs},
keywords = {automatic motion analysis,martial arts,motion,web-based learning},
pages = {239--248},
title = {{e-Learning Martial Arts}},
url = {https://link.springer.com/content/pdf/10.1007{\%}2F11925293{\_}22.pdf},
volume = {4181},
year = {2006}
}
@article{Chan2007,
author = {Chan, Jacky and Leung, Howard and Tang, Kai Tai and Komura, Taku},
doi = {10.4108/ICST.IMMERSCOM2007.2102},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chan et al. - 2007 - Immersive Performance Training Tools Using Motion Capture Technology.pdf:pdf},
isbn = {978-963-9799-06-6},
journal = {Proceedings of the ImmersCom},
keywords = {Immersive VR application, Human Computer Interacti},
title = {{Immersive Performance Training Tools Using Motion Capture Technology}},
url = {http://eudl.eu/doi/10.4108/ICST.IMMERSCOM2007.2102},
year = {2007}
}
@article{Kim2016,
abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}p{\textgreater}Physiologic turnover of interstitial collagen is mediated by a sequential pathway in which collagen is fragmented by pericellular collagenases, endocytosed by collagen receptors, and routed to lysosomes for degradation by cathepsins. Here, we use intravital microscopy to investigate if malignant tumors, which are characterized by high rates of extracellular matrix turnover, utilize a similar collagen degradation pathway. Tumors of epithelial, mesenchymal, or neural crest origin all display vigorous endocytic collagen degradation. The cells engaged in this process are identified as tumor-associated macrophage (TAM)-like cells that degrade collagen in a mannose receptor-dependent manner. Accordingly, mannose-receptor-deficient mice display increased intratumoral collagen. Whole-transcriptome profiling uncovers a distinct extracellular matrix-catabolic signature of these collagen-degrading TAMs. Lineage-ablation studies reveal that collagen-degrading TAMs originate from circulating CCR2+ monocytes. This study identifies a function of TAMs in altering the tumor microenvironment through endocytic collagen turnover and establishes macrophages as centrally engaged in tumor-associated collagen degradation.{\textless}/p{\textgreater}},
author = {Kim, Youngsun and Hong, Seokjun and Kim, Gerard J.},
doi = {10.1145/2993369.2996301},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Hong, Kim - 2016 - Augmented reality based remote coaching system.pdf:pdf},
isbn = {9781450344913},
issn = {22111247},
journal = {Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology - VRST '16},
keywords = {augmented reality,concepts,feedback,human-centered computing,interaction,mixed,multimodal,paradigms,pre-attentive recognition,tele-coaching},
pages = {311--312},
title = {{Augmented reality based remote coaching system}},
url = {http://dl.acm.org/citation.cfm?doid=2993369.2996301},
year = {2016}
}
@article{Hachimura2004,
abstract = { The mixed reality technology, with which scenes of the real world and the virtual world generated by CG are merged in real time, has been drawing considerable attention in the fields of entertainment, manufacturing, and so on. This work presents a prototype support system for dance training and education with the mixed reality technology and motion capture. Several functions which are thought to be significant for dance education, training and learning are devised and evaluated. Some user interface functions for this kind of new interactive systems are also proposed.},
author = {Hachimura, K. and Kato, H. and Tamura, H.},
doi = {10.1109/ROMAN.2004.1374759},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hachimura, Kato, Tamura - 2004 - A prototype dance training support system with motion capture and mixed reality technologies.pdf:pdf},
isbn = {0-7803-8570-5},
issn = {0873-7215},
journal = {RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759)},
pages = {217--222},
pmid = {17308627},
title = {{A prototype dance training support system with motion capture and mixed reality technologies}},
url = {http://ieeexplore.ieee.org/document/1374759/},
year = {2004}
}
@article{Hachimura2005,
abstract = {The final goal of this research is to extract characteristic poses as well as highlight parts from data of dancing movement obtained by motion capturing technique. For this, the theory of Laban movement analysis (LMA) has been applied, and the physical feature values corresponding to the LMA components are defined. By observing the change over time of these feature values, body movements corresponding to the LMA components are extracted. In this paper we mainly focus on effort and shape components of LMA. Results have been compared with those which have been extracted by a LMA specialist.},
author = {Hachimura, Kozaburo and Takashina, Katsumi and Yoshimura, Mitsu},
doi = {10.1109/ROMAN.2005.1513794},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hachimura, Takashina, Yoshimura - 2005 - Analysis and evaluation of dancing movement based on LMA.pdf:pdf},
isbn = {0780392752},
issn = {1944-9445},
journal = {Proceedings - IEEE International Workshop on Robot and Human Interactive Communication},
pages = {294--299},
title = {{Analysis and evaluation of dancing movement based on LMA}},
volume = {2005},
year = {2005}
}
@article{Piumsomboon2017,
abstract = {Figure 1: a) A third-person point of view showing a virtual collaboration between two users in a reconstructed environment, b) System Setup with an AR user on the left in a real environment and VR on the right in a virtual reconstructed environment from the AR side (bottom), AR and VR users were looking at the same block. As they gazed longer together, the color of the block turned red showing that it was not the correct block that they were looking for (top). ABSTRACT We present CoVAR, a novel remote collaborative system combining Augmented Reality (AR), Virtual Reality (VR) and natural communication cues to create new types of collaboration. AR user can capture and share their local environment with a remote user in VR to collaborate on spatial tasks in shared space. COVAR supports various interaction methods to enrich collaboration, including gestures , head gaze, and eye gaze input, and provides virtual cues to improve awareness of a remote collaborator. We also demonstrate collaborative enhancements in VR user's body scaling and snapping to AR perspective. CCS CONCEPTS • Human-centered computing → Mixed / augmented reality;},
author = {Piumsomboon, Thammathip and Lee, Youngho and Lee, Gun and Billinghurst, Mark},
doi = {10.1145/3132818.3132822},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Piumsomboon et al. - 2017 - CoVAR a collaborative virtual and augmented reality system for remote collaboration.pdf:pdf},
isbn = {9781450354042},
journal = {SIGGRAPH Asia 2017 Emerging Technologies on - SA '17},
keywords = {augmented reality,remote collaboration,virtual reality},
pages = {1--2},
title = {{CoVAR a collaborative virtual and augmented reality system for remote collaboration}},
url = {http://dl.acm.org/citation.cfm?doid=3132818.3132822},
year = {2017}
}
@article{Kim2003,
author = {Kim, Tae-Hoon and Park, Sang Il and Shin, Sung Yong},
doi = {10.1145/882262.882283},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Park, Shin - 2003 - Rhythmic-motion synthesis based on motion-beat analysis.pdf:pdf},
isbn = {1581137095},
issn = {07300301},
journal = {{\{}ACM{\}} Trans. Graph.},
keywords = {beat analysis,motion blending,motion signal pro-,motion syn-,motion synchronization,motion transition,thesis},
number = {3},
pages = {392--401},
title = {{Rhythmic-motion synthesis based on motion-beat analysis}},
volume = {22},
year = {2003}
}
@article{Minea,
author = {Mine, Norio and Kai, Tamiko},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mine, Kai - Unknown - Quantification of Characteristic Features of Japanese Dance for.pdf:pdf},
isbn = {0780372220},
pages = {188--193},
title = {{Quantification of Characteristic Features of Japanese Dance for}}
}
@article{Murray-Reichel2004,
abstract = {In this paper, we report a real-time geshire driven interactive system with multimodal feedback for performing arts, especially dance. The system consists of two major paris: a gesture recopifion engine and a multimodal feedhack engine. The gesture recognition engine provides real-time recognition of the performer's geshrre based on the 3 0 marker coordinates from a marker-based motion capture system. According to the recognition results, the muliimodal feedhack engine produces associated visual and audio feedback to the peformer. This interactive system is simple to implement and robust fa errors in 3 0 marker daia. Satisjactory interaciive dance performances have been successfilly created andpresented using the reported system.},
author = {Murray-Reichel, Desmond},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Murray-Reichel - 2004 - I'll reboot the primary EXE program, that should port the SMS alarm!.pdf:pdf},
isbn = {0780386035},
title = {{I'll reboot the primary EXE program, that should port the SMS alarm!}},
year = {2004}
}
@article{Sidharta2005,
abstract = {Cyclone Uppercut is a Virtual Reality (VR) boxing game designed to run in a six sided CAVE-like projection system such as the C6 at Iowa State University. In this game, the player assumes the role of a young boxer fighting in the final match to be the Japanese Rookie Boxer Champion. In the C6's immersive environment, the player uses his/her body to interface with the game. The game play requires the player to dodge enemy's attacks, and to execute various punches to win the game. In this paper we discuss the challenges of creating interfaces to simulate a sport like boxing for an immersive space. We also discuss the philosophy that influences the game play, and followed by the detail of implementation. We argue that the unique design of the game make it an experience that can only be experienced in a fully immersive environment like the C6.},
author = {Sidharta, Ronald and Cruz-Neira, Carolina},
doi = {10.1145/1178477.1178549},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sidharta, Cruz-Neira - 2005 - Cyclone Uppercut, a boxing game for an immersive environment.pdf:pdf},
isbn = {1595931104},
journal = {Ace 2005},
number = {January 2005},
pages = {363--364},
title = {{Cyclone Uppercut, a boxing game for an immersive environment}},
url = {http://delivery.acm.org/10.1145/1180000/1178549/p363-sidharta.pdf?ip=128.243.2.144{\&}id=1178549{\&}acc=ACTIVE SERVICE{\&}key=BF07A2EE685417C5.9530128DD756F5CF.4D4702B0C3E38B35.4D4702B0C3E38B35{\&}CFID=867869100{\&}CFTOKEN=57616277{\&}{\_}{\_}acm{\_}{\_}=1494505749{\_}e837218be5a7a142899},
year = {2005}
}
@article{Bakogianni2007,
abstract = {The WebDANCE project experimented with 3D animation and Webtechnologies, and created a web-learning environment and associated lessons fortraditional dance e-learning. Two dances Karsilamas fromGreece and Valentine Morris from England were used in order to test the approach in two secondary schools.Experience from the WebDANCE project has shown that (a) the sameconceptualization schema can be used to document different European traditional dances, (b) Web3D can be used to create attractive and functionaldance resources, (c) there is a great interest from teachers / trainers in formal and informal educational settings that would like to use theWebDance platform and, (d) there is a great interest from content providers (traditional dance experts) to use the platform in order to documenttraditional dances and create teaching resources.},
author = {Bakogianni, Sophia and Kavakli, Evangelia and Karkou, Vicky and Tsakogianni, Maroussa},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bakogianni et al. - 2007 - Teaching traditional dance using e-learning tools Experience from the WebDance project.pdf:pdf},
journal = {Proceedings DVD of the 21st World Congress on Dance Research},
number = {May 2014},
pages = {1--16},
title = {{Teaching traditional dance using e-learning tools: Experience from the WebDance project}},
year = {2007}
}
@article{DeSilva2004,
abstract = {One of the challenging issues in affective computing is to give a machine the ability to recognize the mood of a person. Efforts in that direction have mainly focused on facial and oral cues. Gestures have been recently considered as well, but with less success. Our aim is to fill this gap by identifying and measuring the saliency of posture features that play a role in affective expression. As a case study, we collected affective gestures from human subjects using a motion capture system. We first described these gestures with spatial features, as suggested in studies on dance. Through standard statistical techniques, we verified that there was a statistically significant correlation between the emotion intended by the acting subjects, and the emotion perceived by the observers. We used Discriminant Analysis to build affective posture predictive models and to measure the saliency of the proposed set of posture features in discriminating between 4 basic emotional states: angry, fear, happy, and sad. An information theoretic characterization of the models shows that the set of features discriminates well between emotions, and also that the models built over-perform the human observers.},
author = {{De Silva}, P. Ravindra and Bianchi-Berthouze, Nadia},
doi = {10.1002/cav.29},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/De Silva, Bianchi-Berthouze - 2004 - Modeling human affective postures An information theoretic characterization of posture features.pdf:pdf},
isbn = {0780344634},
issn = {15464261},
journal = {Computer Animation and Virtual Worlds},
number = {3-4},
pages = {269--276},
title = {{Modeling human affective postures: An information theoretic characterization of posture features}},
volume = {15},
year = {2004}
}
@article{Kojima,
author = {Kojima, Taihei and Hiyama, Atsushi and Miura, Takahiro and Hirose, Michitaka},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/Training Archived Physical Skill through Immersive.pdf:pdf},
keywords = {augmented reality,head mounted display,immersive virtual environment,skill transfer},
pages = {51--58},
title = {{Training Archived Physical Skill through Immersive}}
}
@article{Anonymous2016,
author = {Anonymous, Leave Authors},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/max und ullis chi paper.pdf:pdf},
isbn = {1234567245},
title = {{Guidance , Feedback , and Reflection : Framing the Design Space for Computer-Based Support of Motor Learning}},
year = {2016}
}
@article{Portillo-rodriguez2008,
author = {Portillo-rodriguez, Otniel and Sandoval-gonzalez, Oscar O and Ruffaldi, Emanuele and Leonardi, Rosario and Avizzano, Carlo Alberto and Bergamasco, Massimo},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/Real-Time Gesture Recognition, Evaluation and Feed-.pdf:pdf},
keywords = {audio-position feedback,multimodal interfaces,ognition,real-time 3d time-independent gesture,real-time descriptor,rec-,transfer,vibrotactile feedback,virtual realty and skills},
pages = {30--39},
title = {{Real-Time Gesture Recognition , Evaluation and Feed- Forward Correction of a Multimodal Tai-Chi Platform}},
year = {2008}
}
@article{Chua,
author = {Chua, Philo Tan and Schaaf, Russ},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/Training for Physical Tasks in Virtual Environments Tai Chi.pdf:pdf},
title = {{Training for Physical Tasks in Virtual Environments : Tai Chi}}
}
@article{Yan2015,
author = {Yan, Shuo and Li, Hongsong},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/OutsideMe Augmenting Dancer's.pdf:pdf},
isbn = {9781450331463},
pages = {965--970},
title = {{OutsideMe : Augmenting Dancer ' s External Self-Image by Using A Mixed Reality System}},
year = {2015}
}
@article{Chan2010,
author = {Chan, Jacky C P and Leung, Howard and Tang, Jeff K T and Komura, Taku},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/A Virtual Reality Dance Training System.pdf:pdf},
isbn = {2009120167},
number = {2},
pages = {187--195},
title = {{A Virtual Reality Dance Training System Using Motion Capture Technology}},
volume = {4},
year = {2010}
}
@article{Han2016,
author = {Han, Ping-hsuan and Chen, Kuan-wen and Hsieh, Chen-hsin and Huang, Yu-jie and Hung, Yi-ping},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/AR-Arm Augmented Visualization for Guiding Arm Movement in the First-Person Perspective.pdf:pdf},
keywords = {augmented reality,body movement guidance,visualization,wearable interaction},
pages = {2--5},
title = {{AR-Arm : Augmented Visualization for Guiding Arm Movement in the First-Person Perspective}},
year = {2016}
}
@article{Pfeil2017,
author = {Pfeil, Ulrike and D{\"{u}}rr, Maximilian},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/Einsatzm{\"{o}}glichkeiten von Mixed Reality zur Unterst{\"{u}}tzung.pdf:pdf},
keywords = {kinaesthetics,mixed reality,motorisches lernen},
pages = {11--22},
title = {{Einsatzm{\"{o}}glichkeiten von Mixed Reality zur Unterst{\"{u}}tzung von motorischem Lernen}},
year = {2017}
}
@article{Rajanna2016,
author = {Rajanna, Vijay and Vo, Patrick and Barth, Jerry and Mjelde, Matthew and Grey, Trevor and Oduola, Cassandra and Hammond, Tracy},
doi = {10.1007/s10916-015-0391-3},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/KinoHaptics An Automated, Wearable, Haptic Assisted,.pdf:pdf},
title = {{KinoHaptics : An Automated , Wearable , Haptic Assisted , Physio-therapeutic System for Post-surgery Rehabilitation and Self-care}},
year = {2016}
}
@article{Anderson2013,
author = {Anderson, Fraser and Grossman, Tovi and Matejka, Justin and Fitzmaurice, George},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/YouMove Enhancing Movement Training.pdf:pdf},
isbn = {9781450322683},
pages = {311--320},
title = {{YouMove : Enhancing Movement Training with an Augmented Reality Mirror}},
year = {2013}
}
@article{Ahmad2016,
author = {Ahmad, Akhlaq and Rahman, Mohamed Abdur and Anderson, Fraser and Grossman, Tovi and Matejka, Justin and Dehzangi, Omid and Zhao, Zheng},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/max und ullis chi paper ref.pdf:pdf},
title = {{New York, NY, USA, 3272–3276. DOI:}},
year = {2016}
}
@article{Sodhi2012,
author = {Sodhi, Rajinder},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/LightGuide Projected Visualizations for Hand Movement.pdf:pdf},
isbn = {9781450310154},
pages = {179--188},
title = {{LightGuide : Projected Visualizations for Hand Movement Guidance}},
year = {2012}
}
@article{Kim2014,
author = {Kim, Gerard Jounghyun},
doi = {10.1162/105474602317473240},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/Implementation{\_}and{\_}Evaluation{\_}of{\_}Just{\_}Follow{\_}Me{\_}An.pdf:pdf},
isbn = {1054746023174},
number = {June 2002},
title = {{Implementation and Evaluation of “ Just Follow Me ”: An Immersive , VR-Based , Motion-Training System}},
year = {2014}
}
@article{feyerintegration,
author = {Feyer, Stefan and Siebert, Sophie and Gipp, Bela and Aizawa, Akiko and Beel, Joeran},
title = {{Integration of the Scientific Recommender System Mr. DLib into the Reference Manager JabRef}}
}
@inproceedings{Beel2014c,
abstract = {Mind-maps have been widely neglected by the information retrieval (IR) community. However, there are an estimated two million active mind-map users, who create 5 million mind-maps every year, of which a total of 300,000 is publicly available. We believe this to be a rich source for information retriev- al applications, and present eight ideas on how mind-maps could be utilized by them. For instance, mind-maps could be utilized to generate user models for recommender systems or expert search, or to calculate relatedness of web-pages that are linked in mind-maps. We evaluated the feasibility of the eight ideas, based on estimates of the number of available mind-maps, an analysis of the content of mind-maps, and an evaluation of the users' acceptance of the ideas. We concluded that user modelling is the most promising application with re- spect to mind-maps. A user modelling prototype – a recommender system for the users of our mind-mapping software Docear – was implemented, and evalu- ated. Depending on the applied user modelling approaches, the effectiveness, i.e. click-through rate on recommendations, varied between 0.28{\%} and 6.24{\%}. This indicates that mind-map based user modelling is promising, but not trivial, and that further research is required to increase effectiveness.},
author = {Beel, Joeran and Langer, Stefan and Genzmehr, Marcel and Gipp, Bela},
booktitle = {Proceedings of the 22nd Conference on User Modellin, Adaptation and Personalization (UMAP)},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Beel et al. - 2014 - Utilizing Mind-Maps for Information Retrieval and User Modelling.pdf:pdf},
keywords = {content analysis,information retrieval,mind-maps,user modelling},
title = {{Utilizing Mind-Maps for Information Retrieval and User Modelling}},
url = {http://docear.org/papers/utilizing{\_}mind-maps{\_}for{\_}information{\_}retrieval{\_}and{\_}user{\_}modelling.pdf},
year = {2014}
}
@article{Beel2015,
abstract = {The evaluation of recommender systems is key to the successful application of recommender systems in practice. To evaluate recommender systems, there are three evaluation methods: offline evaluations, online evaluations, and user studies. In this paper, we examine and discuss the appropriateness of the three methods. Among others, we use the three methods to evaluate a number of recommendations approaches in the field of research paper recommendations. The evaluations show that results from offline evaluations sometimes contradict results from online evaluations and user studies. We discuss potential reasons for this, namely the impact of human factors, the potential inherent value of offline evaluations, and the imperfection of offline-datasets, and we conclude that offline evaluations probably are not suitable to evaluate recommender systems, particularly in the domain of research paper recommender systems. We further analyze and discuss the appropriateness of some online evaluation metrics such as click-through rate, link- through rate, and cite-through rate. We conclude that click-through is the most favorable metric, at least in our research, since metrics such as cite-through rate did correlate less well with user satisfaction than click- through rate.},
author = {Beel, Joeran and Langer, Stefan},
doi = {10.1007/978-3-319-24592-8_12},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Beel, Langer - 2015 - A comparison of offline evaluations, online evaluations, and user studies in the context of research-paper recomme.pdf:pdf},
isbn = {9783319245911},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Evaluations,Offline evaluation,Recommender systems,User study},
pages = {153--168},
title = {{A comparison of offline evaluations, online evaluations, and user studies in the context of research-paper recommender systems}},
volume = {9316},
year = {2015}
}
@article{Wesley-smith2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {Wesley-smith, Ian and West, Jevin D},
doi = {10.1145/2872518.2890517},
eprint = {arXiv:1508.06655v1},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wesley-smith, West - 2016 - Babel A Platform for Facilitating Research in Scholarly Article Discovery.pdf:pdf},
isbn = {9781450341448},
journal = {Proceedings of the 25th International Conference Companion on World Wide Web},
keywords = {citation networks,exper-,imentation platforms,information re-,recommenders,scholarly article recommendation},
pages = {389--393},
title = {{Babel : A Platform for Facilitating Research in Scholarly Article Discovery}},
year = {2016}
}
@inproceedings{Kucuktunc:2013:TWA:2467696.2467752,
address = {New York, NY, USA},
author = {K{\"{u}}{\c{c}}{\"{u}}ktun{\c{c}}, Onur and Saule, Erik and Kaya, Kamer and {\c{C}}ataly{\"{u}}rek, {\"{U}}mit V},
booktitle = {Proceedings of the 13th ACM/IEEE-CS Joint Conference on Digital Libraries},
doi = {10.1145/2467696.2467752},
isbn = {978-1-4503-2077-1},
keywords = {citation graph,literature search,paper recommendation,random walk,relevance feedback,result diversification,visualization,web service},
pages = {433--434},
publisher = {ACM},
series = {JCDL '13},
title = {{TheAdvisor: A Webservice for Academic Recommendation}},
url = {http://doi.acm.org/10.1145/2467696.2467752},
year = {2013}
}
@article{Beel2013,
abstract = {In this demo paper we present Docear's research paper recommender system. Docear is an academic literature suite to search, organize, and create research articles. The users' data (papers, references, annotations, etc.) is managed in mind maps and these mind maps are utilized for the recommendations. Using content-based filtering methods, Docear's recommender achieves click-through rates around 6{\%}, in some scenarios even over 10{\%}. Copyright {\&}copy; 2013 by the Association for Computing Machinery, Inc. (ACM).},
author = {Beel, Joeran and Langer, Stefan and Genzmehr, Marcel and N{\"{u}}rnberger, Andreas},
doi = {10.1145/2467696.2467786},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Beel et al. - 2013 - Introducing Docear's research paper recommender system.pdf:pdf},
isbn = {9781450320771},
issn = {15525996},
journal = {Proceedings of the 13th ACM/IEEE-CS joint conference on Digital libraries - JCDL '13},
keywords = {Digital libraries,Paper,Research,Schematic diagram},
pages = {459},
title = {{Introducing Docear's research paper recommender system}},
url = {http://dx.doi.org/10.1145/2467696.2467786{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2467696.2467786},
year = {2013}
}
@inproceedings{Gipp15a,
address = {Newport Beach, California},
author = {Gipp, Bela and Meuschke, Norman and Gernandt, Andre},
booktitle = {Proceedings of the iConference 2015},
title = {{Decentralized Trusted Timestamping using the Crypto Currency Bitcoin}},
url = {http://ischools.org/the-iconference/},
year = {2015}
}
@article{Hart1988,
author = {Hart, Sandra G and California, Moffett Field and Staveland, Lowell E},
doi = {10.1016/S0166-4115(08)62386-9},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hart, California, Staveland - 1988 - Development of NASA-TLX (Task Load Index) Results of Empirical and Theoretical Research.pdf:pdf},
title = {{Development of NASA-TLX (Task Load Index): Results of Empirical and Theoretical Research}},
year = {1988}
}
@article{Geyer2011,
abstract = {Using affinity diagramming as an example, we investigate interaction techniques for supporting collaborative design activities. Based on an observational study, we identified design guidelines that need to be addressed to find a close fit to embodied practice. Using this knowledge, we designed and implemented AffinityTable, a hybrid surface for supporting affinity diagramming. The tool combines digital pen {\&} paper with an interactive table and tangible tokens. An additional vertical display is used to support reflection and group coordination.},
author = {Geyer, Florian and Pfeil, Ulrike and Budzinski, Jochen and H{\"{o}}chtl, Anita and Reiterer, Harald},
doi = {10.1007/978-3-642-23765-2_33},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Geyer et al. - 2011 - AffinityTable - A hybrid surface for supporting affinity diagramming.pdf:pdf},
isbn = {9783642237645},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {affinity diagramming,collaborative design,design tools,digital pen {\&} paper,hybrid interactive surfaces,reality-based interaction},
number = {PART 3},
pages = {477--484},
title = {{AffinityTable - A hybrid surface for supporting affinity diagramming}},
volume = {6948 LNCS},
year = {2011}
}
@phdthesis{Geyer2013Inter-25971,
address = {Konstanz},
author = {Geyer, Florian},
school = {Universit{\"{a}}t Konstanz},
title = {{Interactive Spaces for Supporting Embodied Collaborative Design Practices}},
year = {2013}
}
@book{citeulike:1222233,
abstract = {Bill Buxton and I share a common belief that design leadership together with technical leadership drives innovation. Sketching, prototyping, and design are essential parts of the process we use to create new products. Bill Buxton brings design leadership and creativity to Microsoft. Through his thought-provoking personal examples he is inspiring others to better understand the role of design in their own companies--Bill Gates, Chairman, Microsoft{\textless}br{\textgreater}{\textless}br{\textgreater}Informed design is essential. While it might seem that Bill Buxton is exaggerating or kidding with this bold assertion, neither is the case. In an impeccably argued and sumptuously illustrated book, design star Buxton convinces us that design simply must be integrated into the heart of business--Roger Martin, Dean, Rotman School of Management, University of Toronto{\textless}br{\textgreater}{\textless}br{\textgreater}Design is explained, with the means and manner for successes and failures illuminated by engaging stories, true examples and personal anecdotes. In Sketching User Experiences, Bill Buxton clarifies the processes and skills of design from sketching to experience modeling, in a lively and informative style that is rich with stories and full of his own heart and enthusiasm. At the start we are lost in mountain snows and northern seas, but by the end we are equipped with a deep understanding of the tools of creative design.--Bill Moggridge, Cofounder of IDEO and author of Designing Interactions{\textless}br{\textgreater}{\textless}br{\textgreater}I love this book. There are very few resources available that see across and through all of the disciplines involved in developing great experiences. This is complex stuff and Buxton's work is both informed and insightful. He shares the work in an intimate manner that engages the reader and you will find yourself nodding with agreement, and smiling at the poignant relevance of his examples.--Alistair Hamilton, Symbol Technologies, NY{\textless}br{\textgreater}{\textless}br{\textgreater}Books that have proposed bringing design into HCI are aplenty, though books that propose bringing software in to Design less common. Nevertheless, Bill manages to skilfully steer a course between the excesses of the two approaches and offers something truly in-between. It could be a real boon to the innovation business by bringing the best of both worlds: design and HCI. --Richard Harper, Microsoft Research, Cambridge{\textless}br{\textgreater}{\textless}br{\textgreater}There is almost a fervor in the way that new products, with their rich and dynamic interfaces, are being released to the publictypically promising to make lives easier, solve the most difficult of problems, and maybe even make the world a better place. The reality is that few survive, much less deliver on their promise. The folly? An absence of design, and an over-reliance on technology alone as the solution.{\textless}br{\textgreater}{\textless}br{\textgreater}We need design. But design as described here depends on different skillsetseach essential, but on their own, none sufficient. In this rich ecology, designers are faced with new challengeschallenges that build on, rather than replace, existing skills and practice. {\textless}br{\textgreater}{\textless}br{\textgreater}Sketching User Experiences approaches design and design thinking as something distinct that needs to be better understoodby both designers and the people with whom they need to work in order to achieve success with new products and systems. So while the focus is on design, the approach is holistic. Hence, the book speaks to designers, usability specialists, the HCI community, product managers, and business executives. There is an emphasis on balancing the back-end concern with usability and engineering excellence (getting the design right) with an up-front investment in sketching and ideation (getting the right design). Overall, the objective is to build the notion of informed design: molding emerging technology into a form that serves our society and reflects its values. {\textless}br{\textgreater}{\textless}br{\textgreater}Grounded in both practice and scientific research, Bill Buxtons engaging work aims to spark the imagination while encouraging the use of new techniques, breathing new life into user experience design.{\textless}br{\textgreater}{\textless}br{\textgreater} Covers sketching and early prototyping design methods suitable for dynamic product capabilities: cell phones that communicate with each other and other embedded systems, smart appliances, and things you only imagine in your dreams;{\textless}br{\textgreater} Thorough coverage of the design sketching method which helps easily build experience prototypeswithout the effort of engineering prototypes which are difficult to abandon;{\textless}br{\textgreater} Reaches out to a range of designers, including user interface designers, industrial designers, software engineers, usability engineers, product managers, and others;{\textless}br{\textgreater} Full of case studies, examples, exercises, and projects, and access to video clips that demonstrate the principles and methods.{\textless}br{\textgreater}{\textless}br{\textgreater}About the Author{\textless}br{\textgreater}{\textless}br{\textgreater}Trained as a musician, Bill Buxton began using computers over thirty years ago in his art. This early experience, both in the studio an on stage, helped develop a deep appreciation of both the positive and negative aspects of technology and its impact. This increasingly drew him into both design and research, with a very strong emphasis on interaction and the human aspects of technology. He first came to prominence for his work at the University of Toronto on digital musical instruments and the novel interfaces that they employed. This work in the late 70s gained the attention of Xerox PARC, where Buxton participated in pioneering work in collaborative work, interaction techniques and ubiquitous computing. He then went on to become Chief Scientist of SGI and Alias|Wavefront, where he had the opportunity to work with some of the top film makers and industrial designers in the world. He is now a principal researcher at Microsoft Corp., where he splits his time between research and helping make design a fundamental pillar of the corporate culture.{\textless}br{\textgreater}{\textless}br{\textgreater}* Covers sketching and early prototyping design methods suitable for dynamic product capabilities: cell phones that communicate with each other and other embedded systems, smart appliances, and things you only imagine in your dreams;{\textless}br{\textgreater}{\textless}br{\textgreater}* Thorough coverage of the design sketching method which helps easily build experience prototypeswithout the effort of engineering prototypes which are difficult to abandon;{\textless}br{\textgreater}{\textless}br{\textgreater}* Reaches out to a range of designers, including user interface designers, industrial designers, software engineers, usability engineers, product managers, and others;{\textless}br{\textgreater}{\textless}br{\textgreater}* Full of case studies, examples, exercises, and projects, and access to video clips that demonstrate the principles and methods.},
author = {Buxton, Bill},
edition = {1},
howpublished = {Paperback},
isbn = {0123740371},
keywords = {book,ixd},
month = {apr},
publisher = {Morgan Kaufmann},
title = {{Sketching User Experiences: Getting the Design Right and the Right Design (Interactive Technologies)}},
url = {http://www.worldcat.org/isbn/0123740371},
year = {2007}
}
@book{author,
address = {Rheinzabern},
author = {Linneweh, Klaus},
edition = {7. Aufl.},
keywords = {Kreatives Denken},
publisher = {Gitzel},
title = {{Kreatives Denken: Techniken und Organisation produktiver Kreativität; Kreative Denkprozesse Problemlöseverhalten, Planungssystematik, Techniken der Ideenfindung, soziale Kreativität}},
year = {1999}
}
@misc{Ferguson2012,
author = {Ferguson, Kirby},
title = {{Everything is a Remix}},
url = {http://everythingisaremix.info/watch-the-series/},
urldate = {2015-09-04},
year = {2012}
}
@misc{Feyer2015,
author = {Feyer, Stefan Paul (University of Constance)},
booktitle = {Nursing standard : official newspaper of the Royal College of Nursing},
doi = {10.7748/ns2000.04.14.29.59.c2808},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Feyer - 2015 - Sources of inspiration.pdf:pdf},
issn = {0029-6570},
number = {29},
pages = {59},
pmid = {11309930},
title = {{Sources of inspiration.}},
volume = {1},
year = {2015}
}
@article{Bangor2008,
abstract = {This article presents nearly 10 year's worth of System Usability Scale (SUS) data collected on numerous products in all phases of the development lifecycle. The SUS, developed by Brooke (1996), reflected a strong need in the usability community for a tool that could quickly and easily collect a user's subjective rating of a product's usability. The data in this study indicate that the SUS fulfills that need. Results from the analysis of this large number of SUS scores show that the SUS is a highly robust and versatile tool for usability professionals. The article presents these results and discusses their implications, describes nontraditional uses of the SUS, explains a proposed modification to the SUS to provide an adjective rating that correlates with a given score, and provides details of what constitutes an acceptable SUS score. This article presents nearly 10 year's worth of System Usability Scale (SUS) data collected on numerous products in all phases of the development lifecycle. The SUS, developed by Brooke (1996), reflected a strong need in the usability community for a tool that could quickly and easily collect a user's subjective rating of a product's usability. The data in this study indicate that the SUS fulfills that need. Results from the analysis of this large number of SUS scores show that the SUS is a highly robust and versatile tool for usability professionals. The article presents these results and discusses their implications, describes nontraditional uses of the SUS, explains a proposed modification to the SUS to provide an adjective rating that correlates with a given score, and provides details of what constitutes an acceptable SUS score.},
author = {Bangor, Aaron and Kortum, Philip T. and Miller, James T.},
doi = {10.1080/10447310802205776},
isbn = {1044-7318},
issn = {1044-7318},
journal = {International Journal of Human-Computer Interaction},
number = {6},
pages = {574--594},
title = {{An Empirical Evaluation of the System Usability Scale}},
volume = {24},
year = {2008}
}
@article{Zagermann2015,
author = {Zagermann, Johannes},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zagermann - 2015 - Universit{\"{a}}t Konstanz Department of Computer and Information Science Master Thesis for the degree.pdf:pdf},
title = {{Universit{\"{a}}t Konstanz Department of Computer and Information Science Master Thesis for the degree}},
year = {2015}
}
@article{Shneiderman:2000:CCU:344949.345077,
address = {New York, NY, USA},
author = {Shneiderman, Ben},
doi = {10.1145/344949.345077},
issn = {1073-0516},
journal = {ACM Trans. Comput.-Hum. Interact.},
keywords = {creativity support tools,direct manipulation,graphical user interfaces,human-computer interaction,information visualization},
number = {1},
pages = {114--138},
publisher = {ACM},
title = {{Creating Creativity: User Interfaces for Supporting Innovation}},
url = {http://doi.acm.org/10.1145/344949.345077},
volume = {7},
year = {2000}
}
@article{Brooke1996,
author = {Brooke},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brooke - 1996 - SUS A ‘quick and dirty' usability scale.pdf:pdf},
journal = {In: Jordan, P.W., Thomas, B., Weerdmeester, B.A., McClelland, I.L},
pages = {189--194},
title = {{SUS: A ‘quick and dirty' usability scale}},
url = {http://hell.meiert.org/core/pdf/sus.pdf},
volume = {dustrypp},
year = {1996}
}
@inproceedings{Mueller:2011:DSF:1978942.1979330,
address = {New York, NY, USA},
author = {Mueller, Florian 'Floyd' and Edge, Darren and Vetere, Frank and Gibbs, Martin R and Agamanolis, Stefan and Bongers, Bert and Sheridan, Jennifer G},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1978942.1979330},
isbn = {978-1-4503-0228-9},
keywords = {bodily interaction,exergame,exergaming,exertion interface,kinesthetic,sports,whole-body interaction},
pages = {2651--2660},
publisher = {ACM},
series = {CHI '11},
title = {{Designing Sports: A Framework for Exertion Games}},
url = {http://doi.acm.org/10.1145/1978942.1979330},
year = {2011}
}
@inproceedings{Hornecker:2006:GGT:1124772.1124838,
address = {New York, NY, USA},
author = {Hornecker, Eva and Buur, Jacob},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1124772.1124838},
isbn = {1-59593-372-7},
keywords = {CSCW,analysis,collaboration,design,framework,social interaction,tangible interaction,tangible interface},
pages = {437--446},
publisher = {ACM},
series = {CHI '06},
title = {{Getting a Grip on Tangible Interaction: A Framework on Physical Space and Social Interaction}},
url = {http://doi.acm.org/10.1145/1124772.1124838},
year = {2006}
}
@article{Korhonen2009,
abstract = {It has been commonly acknowledged that the acceptance of a product depends on both its utilitarian and non-utilitarian properties. The non-utilitarian properties can elicit generally pleasurable and particularly playful experiences in the product's users. Product design needs to improve the support of playful experiences in order to fit in with the users' multi-faceted needs. However, designing for fun and pleasure is not an easy task, and there is an urgent need in user experience research and design practices to better understand the role of playfulness in overall user experience of the product. In this paper, we present an initial framework of playful experiences which are derived from studies in interactive art and videogames. We conducted a user study to verify that these experiences are valid. We interviewed 13 videogame players about their experiences with games and what triggers these experiences. The results indicate that the players are experiencing the videogames in many different ways which can be categorized using the framework. We propose that the framework could help the design of interactive products from an experience point of view and make them more engaging, attractive, and most importantly, more playful for the users.},
author = {Korhonen, Hannu and Montola, Markus and Arrasvuori, Juha},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Korhonen, Montola, Arrasvuori - 2009 - Understanding Playful User Experience Through Digital Games.pdf:pdf},
journal = {International Conference on Designing Pleasurable Products and Interfaces},
keywords = {design,digital game,interactive product,playful user experience,playfulness},
number = {October},
pages = {274--285},
title = {{Understanding Playful User Experience Through Digital Games}},
year = {2009}
}
@inproceedings{Schreiner20158636484,
author = {Schreiner, Mario and R{\"{a}}dle, Roman and Jetter, Hans-Christian and Reiterer, Harald},
booktitle = {In Proceedings of the 33rd annual ACM conference extended abstracts on Human factors in computing systems (CHI EA'15)},
month = {apr},
publisher = {ACM},
title = {{Connichiwa - A Framework for Local Cross-Device Web Applications}},
year = {2015}
}
@article{Biskjaer2010,
abstract = {The field of interaction design encompasses a variety of methods for fostering innovation and creativity. In this paper, we present a selection of such methods that scaffold ideation and concept development in the early phases of design. As a conceptual frame for discussing these methods, we introduce four aspects that are particularly salient in the field of interaction design: tradition and transcendence, convergence and divergence, degree of structure, and sources of inspiration. We then outline how the methods relate to each of these aspects. The paper contributes to design practitioners by providing an overview of the methods and insights into when and how they may be employed to foster creativity and innovation in the design process; with regards to design research, the main contribution of the paper lies in the establishment and discussion of the four aspects as a frame for analyzing and comparing design methods},
author = {Biskjaer, Michael Mose and Dalsgaard, Peter and Halskov, Kim},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Biskjaer, Dalsgaard, Halskov - 2010 - Creativity Methods in Interaction Design.pdf:pdf},
journal = {Proceedings of the 1st DESIRE Network Conference on Creativity and Innovation in Design},
number = {August},
pages = {16--17},
title = {{Creativity Methods in Interaction Design}},
url = {http://portal.acm.org/citation.cfm?id=1854976},
year = {2010}
}
@article{Brandt2004,
abstract = {In recent years both companies and research communities call for collaborative work practices and user-centered approaches in various design fields. There are several challenges and issues to take into consideration. For instance there is a need to find ways of collaborating across various competences, interests, responsibilities and perhaps professional languages both within one organization, between several organizations and between the organizations and a group of (potential) users. It is necessary to find ways to learn about users and the contexts of use, and to create a common understanding of the development task. This paper presents a set of four design games, which offers solutions to the challenges mentioned. The design games have been developed in the Space Studio during several projects and years. Here experiences are discussed on the basis of two research projects carried out in collaboration with industrial partners and potential users, and use of the games in three educational settings.The overall aim of the design games is to help facilitate a user-centered design process for cross-disciplinary design groups early in the design process. Framing collaborative design activities in a game format, arguably improves idea generation and communication between stakeholders. By shifting focus to the game, power relations and other factors that might hamper idea generation, are downplayed.},
author = {Brandt, Eva and Messeter, J{\"{o}}rn},
doi = {10.1145/1011870.1011885},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brandt, Messeter - 2004 - Facilitating collaboration through design games.pdf:pdf},
isbn = {1581138512},
journal = {Proceedings of the eighth conference on Participatory design Artful integration interweaving media materials and practices PDC 04},
keywords = {2,collaborative design,design games,empowerment,improving scenario based,stakeholders},
pages = {121--131},
title = {{Facilitating collaboration through design games}},
url = {http://portal.acm.org/citation.cfm?doid=1011870.1011885},
volume = {1},
year = {2004}
}
@article{Mueller2014,
author = {Mueller, Florian and Gibbs, Martin R. and Vetere, Frank and Edge, Darren},
doi = {10.1145/2556288.2557272},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mueller et al. - 2014 - Supporting the creative game design process with exertion cards.pdf:pdf},
isbn = {9781450324731},
journal = {Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI '14},
keywords = {creative process,design cards,exergame,exertion interface,game design,whole-body interaction,workshops},
pages = {2211--2220},
title = {{Supporting the creative game design process with exertion cards}},
url = {http://dl.acm.org/citation.cfm?id=2611205.2557272},
year = {2014}
}
@article{Hornecker2010,
abstract = {I present a card brainstorming exercise that transforms a conceptual tangible interaction framework into a tool for creative dialogue and discuss the experiences made in using it. Ten sessions with this card game demonstrate the frameworks' versatility and utility. Observation and participant feedback highlight the value of a provocative question format and of the metaphor of a card game.},
author = {Hornecker, Eva},
doi = {10.1145/1709886.1709905},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hornecker - 2010 - Creative idea exploration within the structure of a guiding framework the card brainstorming game.pdf:pdf},
isbn = {9781605588414},
journal = {Proceedings of the fourth international conference on Tangible embedded and embodied interaction},
pages = {101--108},
title = {{Creative idea exploration within the structure of a guiding framework: the card brainstorming game}},
url = {http://portal.acm.org.gate6.inist.fr/citation.cfm?id=1709886.1709905{\&}coll=ACM{\&}dl=ACM{\&}CFID=78624755{\&}CFTOKEN=48702884},
volume = {10},
year = {2010}
}
@article{Hallnas2001,
abstract = {As computers are increasingly woven into the fabric of everyday life, interaction design may have to change – from creating only fast and efficient tools to be used during a limited time in specific situations, to creating technology that surrounds us and therefore is a part of our activities for long periods of time. We present slow technology: a design agenda for technology aimed at reflection and moments of mental rest rather than efficiency in performance. The aim of this paper is to develop a design philosophy for slow technology, to discuss general design principles and to revisit some basic issues in interaction design from a more philosophical point of view. We discuss examples of soniture and informative art as instances of slow technology and as examples of how the design principles can be applied in practice.},
author = {Halln{\"{a}}s, Lars and Redstr{\"{o}}m, Johan},
doi = {10.1007/PL00000019},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Halln{\"{a}}s, Redstr{\"{o}}m - 2001 - Slow technology - designing for reflection.pdf:pdf},
isbn = {1617-4909},
issn = {16174909},
journal = {Personal and Ubiquitous Computing},
keywords = {Design,Human-computer interaction,Informative art,Slow technology,Soniture,Ubiquitous computing},
number = {3},
pages = {201--212},
title = {{Slow technology - designing for reflection}},
volume = {5},
year = {2001}
}
@article{Hansen2012,
abstract = {Physical design artefacts are employed in a wide range of participatory design events, yet there are few comprehensive discussions of the properties and qualities of them in the literature of the field. In this paper, we examine the productive role of material design artefacts in participatory design events. First, we offer a theoretical foundation for understanding material artefacts in design, based on pragmatist philosophy. Then, we employ this theoretical perspective to analyse a case in which a range of physical design materials was employed to envision and explore a projected building, the “Urban Media Space” a new library in Aarhus, Denmark. Drawing on examples from this case, we define a series of design considerations for employing material design artefacts in collaborative design events. Our contribution is valuable both in advancing the theoretical standpoint of interaction design in general, and in allowing participatory design practitioners to reflect on their use of material design artefacts when involving users.},
author = {Hansen, Nicolai Brodersen and Dalsgaard, Peter},
doi = {10.1145/2399016.2399117},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hansen, Dalsgaard - 2012 - The productive role of material design artefacts in participatory design events.pdf:pdf},
isbn = {9781450314824},
journal = {Proceedings of the 7th Nordic Conference on Human-Computer Interaction Making Sense Through Design - NordiCHI '12},
keywords = {Design process,Physical artifacts,prototyping},
pages = {665--674},
title = {{The productive role of material design artefacts in participatory design events}},
url = {http://dl.acm.org/citation.cfm?doid=2399016.2399117},
year = {2012}
}
@article{Oehlberg2012,
author = {Oehlberg, Lora and Simm, Kyu and Jones, Jasmine and Agogino, Alice and Hartmann, Bj{\"{o}}rn},
doi = {10.1145/2317956.2318057},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Oehlberg et al. - 2012 - Showing is sharing.pdf:pdf},
isbn = {9781450312103},
journal = {Proceedings of the Designing Interactive Systems Conference on - DIS '12},
keywords = {CSCW,creativity support,design teams,shared display},
pages = {669},
title = {{Showing is sharing}},
url = {http://dl.acm.org/citation.cfm?id=2317956.2318057},
year = {2012}
}
@article{Kwiatkowska2014,
author = {Kwiatkowska, Joanna},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kwiatkowska - 2014 - ( Un ) structured Sources of Inspiration Comparing the Effects of Game-like Cards and Design Cards on Creativity i.pdf:pdf},
isbn = {9781450322560},
journal = {Pdc '14},
number = {2010},
pages = {31--39},
title = {{( Un ) structured Sources of Inspiration : Comparing the Effects of Game-like Cards and Design Cards on Creativity in Co-design Process}},
year = {2014}
}
@article{Beck2008,
author = {Beck, Elke and Obrist, Marianna and Bernhaupt, Regina and Tscheligi, Manfred},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Beck et al. - 2008 - Instant Card Technique How and Why to apply in User-Centered Design.pdf:pdf},
isbn = {9780981856100},
journal = {Proceedings Participatory Design Conference},
keywords = {3,and dalsg{\aa}rd,concepts,halskov,of,suggest creating further categories,the creation of design,triggers of ideas in},
pages = {162--165},
title = {{Instant Card Technique: How and Why to apply in User-Centered Design}},
year = {2008}
}
@article{Wahid2010,
abstract = {Artifacts can be used to inspire, guide, and create new designs. As approaches to design can range from focusing on inspiration to formalized reasoning, we seek to create and study artifacts that combine the use of images and rationale. In this paper, we contribute an understanding of the relationship between imagery and rationale through an investigation of an artifact made of both. Through a study of group design sessions, we find images can provide access to rationale, moments of inspiration can be balanced with rationale, and differences between images and rationale must be reconciled. We conclude with thoughts on how such artifacts might be leveraged by the design community.},
author = {Wahid, Shahtab and Branham, Stacy M and Mccrickard, D Scott and Harrison, Steve and Tech, Virginia},
doi = {10.1145/1858171.1858187},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wahid et al. - 2010 - Investigating the Relationship Between Imagery and Rationale in Design.pdf:pdf},
isbn = {9781450301039},
journal = {Human-Computer Interaction},
pages = {75--84},
title = {{Investigating the Relationship Between Imagery and Rationale in Design}},
year = {2010}
}
@article{Guiford1950,
abstract = {I DISCUSS the subject of creativity with consid- erable hesitation, for it represents an area in which psychologists generally, whether they be angels or not, have feared to tread. It has been one of my long-standing ambitions, however, to under- take an investigation of creativity. Circumstances have just recently made possible the realization of that ambition.2 But the work has been started only within the past year. Consequently, if you are expecting answers based upon new empirical re- search you will be disappointed. What I can do at this time is to describe the plans for that re- search and to report the results of considerable thinking, including the hypotheses at which my students and I have arrived after a survey of the field and its problems. The research design, al- though not essentially new, should be of some in- terest. I will also point out some implications of the problems of creativity in vocational and edu- cational practices.},
author = {Guiford, J P},
doi = {10.1037/h0063487},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guiford - 1950 - Creativity.pdf:pdf},
isbn = {0003-066X$\backslash$r1935-990X},
issn = {0003-066X},
journal = {American psychologist},
pages = {444--454},
pmid = {14553846},
title = {{Creativity}},
volume = {5},
year = {1950}
}
@article{Hochtl2012,
author = {H{\"{o}}chtl, Anita},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/H{\"{o}}chtl - 2012 - Supporting methodic design practices with interactive organization and visualization of design artifacts.pdf:pdf},
title = {{Supporting methodic design practices with interactive organization and visualization of design artifacts}},
year = {2012}
}
@article{Halskov2006,
abstract = {In this paper we start from the position that sources of inspiration play an important role in the design process albeit in a frequently intangible way. We present the Inspiration Card Workshop as a collaborative method for combining findings from domain studies, represented in Domain Cards, with sources of inspiration from applications of technology, represented in Technology Cards, to create new concepts for design. We report our findings from three projects in which we have used the method and argue that Inspiration Cards can successfully the use frame of and guide workshops with disparate participants and bring various sources of inspiration into the design process. We furthermore compare the method to four related methods in the design process, namely Future Workshops, Metaphorical Design, Interaction Relabelling and Lateral Thinking.},
author = {Halskov, Kim and Dalsg{\aa}rd, Peter},
doi = {http://doi.acm.org/10.1145/1142405.1142409},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Halskov, Dalsg{\aa}rd - 2006 - Inspiration card workshops.pdf:pdf},
isbn = {1595933417},
journal = {Proceedings of the 6th conference on Designing Interactive systems},
keywords = {2,acm classification keywords,design,e,g,h5,hci,information interfaces and presentation,innovation,inspiration,workshop},
pages = {2--11},
title = {{Inspiration card workshops}},
year = {2006}
}
@article{Buur2000,
abstract = {In User Centred Design, the integration of knowledge of users work$\backslash$npractice, preferences etc. into the design process is crucial to$\backslash$nsuccess. For this reason, video recording has become a widespread$\backslash$ntool for documenting user activities observed in field studies, usability$\backslash$ntests and user workshops. To make sense of video recordings - though$\backslash$na rewarding experience - is time consuming and mostly left to experts.$\backslash$nEven though developers may ask for expert advice on usability matters,$\backslash$nchances are that they will not follow it, given the technical and$\backslash$ncommercial trade-offs in every project.$\backslash$n$\backslash$nIn this paper we will argue that, to achieve user friendly products,$\backslash$nworking with user video should be an integral part of the activities$\backslash$nof the design team, not a specialised task of experts. To support$\backslash$nthis, video must be made available as a resource in design discussions$\backslash$nand developers must be allowed to form their own understanding and$\backslash$nconclusions. This paper presents a technique for turning video into$\backslash$ntangible arguments to support design teams work. Furthermore it discusses$\backslash$nhow this technique can be improved with Augmented Reality and presents$\backslash$nan augmented prototype session.},
author = {Buur, Jacob and Soendergaard, Astrid},
doi = {http://doi.acm.org/10.1145/354666.354673},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Buur, Soendergaard - 2000 - Video card game an augmented environment for user centred design discussions.pdf:pdf},
isbn = {1581133677},
journal = {Proceedings of DARE 2000 on Designing augmented reality environments},
keywords = {augmented reality environment,collaborative design,user centred design,video analysis},
pages = {63--69},
title = {{Video card game: an augmented environment for user centred design discussions}},
url = {http://doi.acm.org/10.1145/354666.354673},
year = {2000}
}
@article{Weber2014,
author = {Weber, David},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Weber - 2014 - Post-Wimp Audio Browsing ¨ glichkeiten der Neue M o ¨ nden Exploration von Audiobest a in Bibliotheken.pdf:pdf},
number = {April},
title = {{Post-Wimp Audio Browsing : ¨ glichkeiten der Neue M o ¨ nden Exploration von Audiobest a in Bibliotheken}},
year = {2014}
}
@article{Lucero2010,
abstract = {Playfulness can be observed in all areas of human activity. It is an attitude of making activities more enjoyable. Designing for playfulness involves creating objects that elicit a playful approach and provide enjoyable experiences. In this paper we introduce the design and evaluation of the PLEX Cards and its two related idea generation techniques. The cards were created to communicate the 22 categories of a Playful Experiences framework to designers and other stakeholders who wish to design for playfulness. We have evaluated the practical use of the cards by applying them in three design cases. The results show that the PLEX Cards are a valuable source of inspiration when designing for playfulness and the techniques help create a large amount of ideas in a short time.},
author = {Lucero, Andr{\'{e}}s and Arrasvuori, Juha},
doi = {10.1145/1823818.1823821},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lucero, Arrasvuori - 2010 - PLEX Cards A Source of Inspiration When Designing for Playfulness.pdf:pdf},
isbn = {9781605589077},
issn = {17548853},
journal = {Fun and Games},
keywords = {card,design methods,inspiration,playfulness,workshop},
number = {17},
pages = {28--37},
title = {{PLEX Cards : A Source of Inspiration When Designing for Playfulness}},
volume = {15},
year = {2010}
}
@article{Dayton,
author = {Dayton, Tom},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dayton - Unknown - a C . a . R . D . Game for Participatory Task Analysis and Redesign Macroscopic Complement To Pictive.pdf:pdf},
journal = {Techniques},
keywords = {design,participatory,pictive,task analysis},
pages = {51--52},
title = {{a C . a . R . D . Game for Participatory Task Analysis and Redesign : Macroscopic Complement To Pictive}}
}
@article{Huyghe2014,
author = {Huyghe, Jonathan and Wouters, Niels and Geerts, David and {Vande Moere}, Andrew},
doi = {10.1145/2559206.2581348},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huyghe et al. - 2014 - LocaLudo card-based workshop for interactive architecture.pdf:pdf},
isbn = {9781450324748},
journal = {Proceedings of the extended abstracts of the 32nd annual ACM conference on Human factors in computing systems - CHI EA '14},
keywords = {codesign,community,participatory design,playful design,public space,urban informatics,workshop},
pages = {1975--1980},
title = {{LocaLudo: card-based workshop for interactive architecture}},
url = {http://dl.acm.org/citation.cfm?id=2611780.2581348},
year = {2014}
}
@article{Reinoso2016,
author = {Hoang, Thuong N and Reinoso, Martin and Vetere, Frank and Tanin, Egmen},
file = {:C$\backslash$:/Users/stefa/OneDrive/Master Arbeit/Literatur/Onebody Remote Posture Guidance System using First Person View in Virtual Environment.pdf:pdf},
isbn = {9781450347},
title = {{Onebody : Remote Posture Guidance System using First Person View in Virtual Environment}},
year = {2016}
}
@article{Wang2001,
abstract = {Dynamic viewpoint tethering is an innovative display technique which has been proposed to support effective navigation in large-scale virtual environments, by integrating information from different frames of reference. The present study examines the effect of dynamic viewpoint tethering on performance, with respect to both local guidance and global awareness measures, in comparison with three conventional display formats: egocentric, exocentric and rigidly tethered displays. Participants were instructed to control an aircraft-shaped cursor navigating in a virtual tunnel and to answer questions about the environment. The results confirmed that global awareness performance decreased with increased egocentricity in the display frame of reference. The two tethered displays (dynamic and rigid) supported the best local guidance performance. No significant performance differences were found between the two tethered displays.},
author = {Wang, Wenbi and Milgram, Paul},
doi = {10.1177/154193120104502702},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Milgram - 2001 - Dynamic Viewpoint Tethering for Navigation in Large-scale Virtual Environments.pdf:pdf},
issn = {1071-1813},
journal = {Human Factors},
keywords = {awareness,dynamically tethered displays,navigation,virtual cameras,virtual environments},
pages = {1862--1866},
title = {{Dynamic Viewpoint Tethering for Navigation in Large-scale Virtual Environments}},
year = {2001}
}
@article{Deng2014,
author = {Deng, Ying and Antle, Alissa N. and Neustaedter, Carman},
doi = {10.1145/2598510.2598601},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Deng, Antle, Neustaedter - 2014 - Tango cards.pdf:pdf},
isbn = {9781450329026},
journal = {Proceedings of the 2014 conference on Designing interactive systems - DIS '14},
keywords = {design cards,design practice,design tools,educational games,tangible learning games,tangible user interfaces},
pages = {695--704},
title = {{Tango cards}},
url = {http://dl.acm.org/citation.cfm?id=2598510.2598601},
year = {2014}
}
@article{Perteneder2012,
author = {Perteneder, Florian and Grossauer, Christian and Seifried, Thomas and Walney, Jagoda and Brosz, John and Tang, Anthony and Carpendale, Sheelagh and Haller, Michael},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Perteneder et al. - 2012 - Idea Playground When Brainstorming is Not Enough.pdf:pdf},
journal = {Proceedings of the workshop Blended Interaction in Conjunction with the Conference on Advanced visual interfaces AVI 2012},
keywords = {brainstorming,design process,interac-,interactive environment,multi-user input,pen input,tive surface},
number = {Figure 2},
title = {{Idea Playground : When Brainstorming is Not Enough}},
year = {2012}
}
@article{Dalsgaard2014,
author = {Dalsgaard, Peter},
file = {:C$\backslash$:/Users/stefa/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dalsgaard - 2014 - Environments for Creative Interaction Design Processes.pdf:pdf},
isbn = {9781450329033},
pages = {211--214},
title = {{Environments for Creative Interaction Design Processes}},
year = {2014}
}
@inproceedings{Muckell2017,
author = {Muckell, Jonathan and Young, Yuchi and Leventhal, Mitch},
year = {2017},
month = {07},
pages = {202-206},
title = {A Wearable Motion Tracking System to Reduce Direct Care Worker Injuries: An Exploratory Study},
doi = {10.1145/3079452.3079493}
}
